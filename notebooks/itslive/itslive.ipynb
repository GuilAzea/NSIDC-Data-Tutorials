{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"> \n",
    "<img src='./img/header.png'/>\n",
    "</div>\n",
    "\n",
    "## [Global Ice Velocities](https://its-live.jpl.nasa.gov/)\n",
    "    \n",
    "The Inter-mission Time Series of Land Ice Velocity and Elevation (ITS_LIVE) project facilitates ice sheet, ice shelf and glacier research by providing a globally comprehensive and temporally dense multi-sensor record of land ice velocity and elevation with low latency.\n",
    "\n",
    "Scene-pair velocities generated from satellite optical and radar imagery.\n",
    "\n",
    "* Coverage: All land ice\n",
    "* Date range: 1985-present\n",
    "* Resolution: 240m\n",
    "* Scene-pair separation: 6 to 546 days\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "* If you want to query our API directly using  your own software here is the OpenApi endpoint https://staging.nsidc.org/apps/itslive-search/docs\n",
    "* For questions about this notebook and the dataset please contact users services at uso@nsidc.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: We are importing the its_live class and supresing non essential warnings\n",
    "from itslive import itslive_ui\n",
    "ui = itslive_ui('north')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2: Now let's render our UI and pick up an hemisphere, if you update the hemisphere you need to execute the cell again.\n",
    "ui.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3: We build the parameters to query the ITS_LIVE Search API, we get the time coverage for our selected area\n",
    "params = ui.build_params()\n",
    "print(f'current parameters: {params}')\n",
    "timeline = None\n",
    "if params is not None:\n",
    "    timeline = ui.update_coverages()\n",
    "    total =  sum(item['count'] for item in timeline)\n",
    "    print(f'Total data granules: {total:,}')\n",
    "timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4: Now we are going to get the velocity pair urls\n",
    "params = ui.build_params()\n",
    "if params is not None:\n",
    "    urls = ui.get_granule_urls()\n",
    "    # Print the first 10 granule URLs\n",
    "    for url in urls[0:10]:\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5: This will query AWS(where the granules are stored) so we know the total size of our first N granules\n",
    "# This may take some time, try reducing the selected area or constraining the other parameters to download a reasonable number of granules.\n",
    "max_granules = 100\n",
    "sizes = ui.calculate_file_sizes(max_granules)\n",
    "total_zise = round(sum(sizes)/1024,2)\n",
    "print(f'Approx size to download for the first {max_granules:,} granules: {total_zise} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "**Now that we have our list of data granules we can download them from AWS.**\n",
    "\n",
    "If this notebook is running inside AWS we could load the granules into a Dask cluster and reduce our processing times and costs.\n",
    "Let's get some coffee, some data requests are in the Gigabytes realm and may take a little while to be processed. \n",
    "Once that your status URL says is completed we can grab the HDF5 data file using the URL on the same response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ui.download_velocity_pairs(0,100)\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "# ds = xr.open_mfdataset('data*/*.nc', combine='by_coords')\n",
    "ds = xr.open_dataset('data/' + files[0])\n",
    "\n",
    "ds.plot.scatter(x='vx',y='vy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
