{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data Visualization\n",
    "Valkyrie and Icesat 2 data are by nature big data sets that require some special considerations when working with it. The main constraint if you don't have a super computer is memory. The average granule size is in the 10s of MB for IceSat 2 and could be Gigabytes in Valkyrie depending on the order/subsetting. \n",
    "\n",
    "This is when libraries like Dask, Vaex and others come into play. This notebook will show you how to use some basic plotting techniques using matpplotlib and geopandas + Vaex to work effectively with lidar data from Valkyrie and ATL data from IceSat 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import glob\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import vaex\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "from iceflow.processing import IceFlowProcessing as ifp\n",
    "# gibs = 'https://gibs.earthdata.nasa.gov/wmts/epsg3413/best/1.0.0/WMTSCapabilities.xml'\n",
    "\n",
    "# filepath = 'data/atm1b_data_2020-07-10T15-32.hdf5'\n",
    "# df_k = ifp.get_common_dictionary('ATM')\n",
    "\n",
    "filepath = 'data/twaties-test-GLAH06-2000-2010.h5'\n",
    "df_k = ifp.get_common_dictionary('GLASS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data with H5PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "f = h5py.File(filepath, 'r')\n",
    "print(list(f.keys()))\n",
    "\n",
    "\n",
    "df = ifp.get_common_df(f)\n",
    "display(df.describe())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask + GeoPandas\n",
    "Pandas is amazing! but sometimes not optimized for big dataframes... enter DASK! \n",
    "\n",
    "**TODO**: DASK implementation, cluster version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vaex \n",
    "\n",
    "* Using VAEX to visualize big data frames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = vaex.open(filepath)\n",
    "# We're parsing the utc_datetime from Valkyrie into a data type that Vaex understands.\n",
    "df['date'] = df.utc_datetime.values.astype('datetime64[ns]')\n",
    "# my_df = df['longitude', 'latitude', 'elevation', 'date']\n",
    "my_df = df[df_k['latitude'], df_k['longitude'], df_k['elevation'], 'date']\n",
    "# vaex.vrange() is like numpy.arange but uses 0-memory no matter the length.\n",
    "# This is to downsample the data for dataviz see: https://github.com/vaexio/vaex/issues/911\n",
    "df.add_column('index', vaex.vrange(0, len(df)))\n",
    "# We are going to create a \"decimated\" dataframe with only 1/100 of the size of the original to plot the big picture faster.\n",
    "df_decimated = df[(df.index % 100 == 0)]\n",
    "my_df.describe()\n",
    "display(my_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the big picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.widget.heatmap(my_df.longitude, \n",
    "               my_df.latitude,\n",
    "               what=vaex.stat.mean(my_df.elevation),\n",
    "               shape=512, \n",
    "               figsize=(10,6),\n",
    "               limits='minmax',\n",
    "               colormap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import vaex\n",
    "from ipywidgets import widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "plt.figure(figsize=(10,8), dpi= 90)\n",
    "ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=0)) \n",
    "ax.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax.set_extent([-50, -40, 60, 90], ccrs.PlateCarree())\n",
    "plt.scatter(df_decimated.longitude.values,\n",
    "            df_decimated.latitude.values,\n",
    "            c=df_decimated.elevation.values,\n",
    "            cmap='viridis',\n",
    "            vmin=100,vmax=1000,\n",
    "            transform=ccrs.PlateCarree())\n",
    "plt.colorbar(label='elevation', shrink=0.5, extend='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Flying\" with the sensor to get a closer look on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(70, 70)\n",
    "\n",
    "def plot_func(alontrack):\n",
    "    step = 5000 # same as density\n",
    "    m = int(alontrack * step)\n",
    "    ax.clear()\n",
    "    ax.scatter(df.longitude.values[m:m+step],\n",
    "               df.latitude.values[m:m+step],\n",
    "               df.elevation.values[m:m+step],\n",
    "               c=df.elevation.values[m:m+step],\n",
    "               cmap='viridis', s=1)\n",
    "    ax.axis('tight')\n",
    "    \n",
    "    \n",
    "\n",
    "interact(plot_func, alontrack = widgets.FloatSlider(value=0,\n",
    "                                                    description='Along Track Steps',\n",
    "                                                    min=0,\n",
    "                                                    max=90,\n",
    "                                                    step=0.3,\n",
    "                                                    layout={'width': '100%'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series\n",
    "\n",
    "After harmonizing data from Pre-IB, IS1, IceBridge, IS2 we should be able to grid and or concatenate the dataframes and start building real analyses.\n",
    "\n",
    "Ideas: \n",
    "\n",
    "* Use Numba when possible\n",
    "* Dask deployed in DAACs not AWS\n",
    "* Extend VAEX ala GeoPandas, proposed name: GeoVAEX\n",
    "* Explore https://github.com/davidbrochart/xarray_leaflet\n",
    "* See if IRIS can be used here ALA Pangeo.\n",
    "* **Pangeo All the Things!!!**\n",
    "\n",
    "\n",
    "<img src='./img/unfinished_horse.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
