{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# *IceFlow & icepyx*: Altimetry Time Series Tutorial\n",
    "### NASA Earthdata Webinar - April 2021</b>\n",
    "\n",
    "This tutorial demonstrates how to harmonize several NASA altimetry data sets with varying temporal coverage, formats, and coordinate reference frames using the IceFlow and icepyx Python tools. Please refer to the 0_introduction.ipynb notebook for detailed information on the data sets you will be exploring in this tutorial. \n",
    "\n",
    "#### Objectives:\n",
    "1. Use the IceFlow map widget to select and visualize an area of interest.\n",
    "2. Access coincident ICESat/Glas, Operation IceBridge, and ICESat-2 data over the same spatial region.\n",
    "3. Use the community-developed icepyx python library to subset ICESat-2 data.\n",
    "4. Learn about advanced icepyx capabilities including data value visualization prior to download. \n",
    "5. Extract common data variables into a Geopandas dataframe.\n",
    "7. Plot and visualize the altimetry time series to detect glacial elevation change over time.\n",
    "\n",
    "<b>Authors:</b><br />\n",
    "<span style=\"font-size:larger;\">Jessica Scheick</span>, *University of New Hampshire*, Durham, New Hampshire<br />\n",
    "<span style=\"font-size:larger;\">Nicholas Kotlinski & Amy Steiker</span>, *NASA National Snow and Ice Data Center DAAC*, Boulder, Colorado, USA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Running this tutorial locally\n",
    "\n",
    "To run this notebook locally, you must first set up your computing environment. Please see the [repository readme](https://github.com/nsidc/NSIDC-Data-Tutorials#usage-with-binder) for instructions on several ways (using Binder, Docker, or Conda) to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. NASA's Earthdata Credentials\n",
    "\n",
    "To access data using the *IceFlow* library and *icepyx* package, it is necessary to log into [Earthdata Login](https://urs.earthdata.nasa.gov/). To do this, enter your NASA Earthdata credentials in the next step after executing the following code cell.\n",
    "\n",
    "**Note**: If you don't have NASA Earthdata credentials you will need to register first at the link above. An account is free and available to everyone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# This cell will prompt you for your Earthdata username and password. Press\n",
    "from iceflow.ui import IceFlowUI\n",
    "client = IceFlowUI()\n",
    "client.display_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This cell will verify if your credentials are valid. \n",
    "# This may take a little while. If it fails, please try again.\n",
    "\n",
    "authorized = client.authenticate()\n",
    "if authorized is None:\n",
    "    print('Earthdata Login not successful')\n",
    "else:\n",
    "    print('Earthdata Login successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Note:** If the output shows \"You are logged into NASA Earthdata!\", then you are ready to proceed!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. Accessing and harmonizing data across missions\n",
    "#### 2.1. Accessing Data with the *IceFlow* Access Widget\n",
    "The *IceFlow* access widget is a user interface tool to visualize flightpaths from IceBridge, draw a region of interest, set spatio-temporal parameters and place data orders to the *IceFlow* API and *icepyx* package without the need to writing code.\n",
    "The output of the operations performed in the widget can be seen in the log window (right-most icon at the bottom of your browser.) \n",
    "<img src='./img/log-icons.png'> or by selecting it on the View menu \"Show log console\"\n",
    "\n",
    "**Note:** The access widget is currently stateless, so if you change any parameter you will have to redraw your bounding box or polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's start with the user interface. Using 'horizontal' will add the widget inline.\n",
    "client.display_map('horizontal', extra_layers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2.2. Accessing data with the *IceFlow* API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo: Need to explain what the itrf and epoch values are and which ones are best to utilize in conjunction with ICESat-2 analysis. \n",
    "\n",
    "### For Jessica's clarification (and maybe others')?\n",
    "ICESat = GLAH06 (GLAS sensor)\n",
    "\n",
    "pre-IceBridge = ATM\n",
    "\n",
    "IceBridge = ILVIS2\n",
    "\n",
    "ICESat-2 = ATL0X (ATLAS sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Small example subset over Sermeq Kujalleq (Jakobshavn Isbrae):\n",
    "my_params1 ={\n",
    "    'datasets': ['GLAH06', 'ILVIS2', 'ATL06'],\n",
    "    'start': '2007-01-01',\n",
    "    'end': '2018-12-31',\n",
    "    'bbox': '-49.6,69.1,-49.3,69.17',\n",
    "\n",
    "    # Here we will select ITRF2014 to match ICESat-2 an Epoch of the most recent ICESat-2 granule we are ordering\n",
    "    'itrf': 'ITRF2014',\n",
    "    'epoch': '2018.12'\n",
    "}\n",
    "\n",
    "# returns a json dictionary, the request parameters and the order's response.\n",
    "granules_metadata = client.query_cmr(params=my_params1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the IceBridge data is so dense, we order a smaller subset to decrease order and download times\n",
    "my_params2 ={\n",
    "    'datasets': ['ATM1B'],\n",
    "    'start': '2007-01-01',\n",
    "    'end': '2018-12-31',\n",
    "    'bbox': '-49.53,69.12,-49.51,69.135',\n",
    "    # Here we will select ITRF2014 to match ICESat-2 an Epoch of the most recent ICESat-2 granule we are ordering\n",
    "    'itrf': 'ITRF2014',\n",
    "    'epoch': '2018.12'\n",
    "}\n",
    "\n",
    "# returns a json dictionary, the request parameters and the order's response.\n",
    "granules_metadata = client.query_cmr(params=my_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "orders1 = client.place_data_orders(params=my_params1)\n",
    "print(orders1)\n",
    "orders2 = client.place_data_orders(params=my_params2)\n",
    "print(orders2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Check Order Status\n",
    "The following cell will show you the status of your data order. You can proceed in the notebook once all orders are \"COMPLETE\". If you proceed earlier only the completed data orders will be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for order in orders1:\n",
    "    status = client.order_status(order)\n",
    "    print(order['dataset'], order['id'], status['status'])\n",
    "    \n",
    "for order in orders2:\n",
    "    status = client.order_status(order)\n",
    "    print(order['dataset'], order['id'], status['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Download Data\n",
    "Once all data orders are \"COMPLETE\", you can proceed downloading the data. The data are downloaded to the /data folder of this notebook directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for order in orders1:\n",
    "    status = client.order_status(order)\n",
    "    if status['status'] == 'COMPLETE':\n",
    "        client.download_order(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for order in orders2:\n",
    "    status = client.order_status(order)\n",
    "    if status['status'] == 'COMPLETE':\n",
    "        client.download_order(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2.3. Downloading ICESat-2 data [directly] with *icepyx*\n",
    "Behind the scenes, *IceFlow* is using the [*icepyx*](https://icepyx.readthedocs.io/en/latest/) Python package to download ICESat-2 data. *icepyx* is a standalone library that includes its own examples and documentation and welcomes contributions from data users (no previous GitHub or software development experience required!). Thus, it has a lot of additional functionality for querying, subsetting, ordering, and downloading ICESat-2 datasets (with in-the-works additions for data ingest into multiple formats), including making it easier to programmatically download data from multiple regions. Here we highlight some of the data visualization capabilities for exploring data prior to order and download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the icepyx query object and import icepyx\n",
    "# Note: if you would like to order additional ICESat-2 data using icepyx, you'll need to attach an Earthdata\n",
    "# session to your icepyx query object (or re-login to Earthdata). See [icepyx examples](https://icepyx.readthedocs.io/en/latest/getting_started/example_link.html) for more details.\n",
    "import icepyx as ipx\n",
    "bbox_list = [float(val) for val in (my_params1[\"bbox\"].split(\",\"))]\n",
    "is2_obj = ipx.Query(str(my_params1[\"datasets\"][-1]), bbox_list, [my_params1[\"start\"], my_params1[\"end\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the query extent (this map won't be interactive if you don't have geoviews and the dev version of icepyx installed)\n",
    "# Thus, for very small areas it can be difficult to see the specified region on a static world map (an area for future development!)\n",
    "is2_obj.visualize_spatial_extent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Working with the data\n",
    "Now that we have downloaded our data, we need to make sure that they are in a common format to do analysis across missions.\n",
    "\n",
    "Although typically we would include all import statements at the start of the workflow, here we have separated them into this section for instructional clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Jessica update**: why are we ignoring warnings? I addressed the rest of the comments \n",
    "\n",
    "**Amy Note**: We should explain the libraries we're importing briefly. I generally think it's better practice to put all imports at the very top of the notebook but I don't have any documentation on hand to back that up! In particular we shuold explain why wer're ignoring warnings (and this could probably be in the same code block as the previous block). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs #geospatial (mapping) plotting library\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import geopandas as gpd #add geospatial awareness/functionality to pandas\n",
    "from iceflow.processing import IceFlowProcessing as ifp\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt #Python visualization\n",
    "import pandas as pd #data analysis and manipulation tool\n",
    "import warnings #Python warnings module\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/ILVIS2-20210422-6a3b3ac4-f1f9-40a0-b19d-7b34022e0960.h5', 'r') as h5:\n",
    "    print(h5.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We don't have a reader for the ILVIS data - should we not download it then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-IceBridge ATM granule data\n",
    "preib_gdf = ifp.to_geopandas('data/ATM1B-20210423-8fc1edba-1022-4fa1-937b-43d3457fbd93.h5')\n",
    "preib_gdf['mission'] = \"IB\"\n",
    "\n",
    "# We don't have a reader for the ILVIS data\n",
    "# preib_gdf = ifp.to_geopandas('data/ILVIS2-20210423-c099b967-fd33-4104-85fc-11b0edc218c5.h5)\n",
    "# preib_gdf['mission'] = \"IB\"\n",
    "\n",
    "# ICESat granule data\n",
    "glas_gdf = ifp.to_geopandas('data/GLAH06-20210423-dc59a3db-e79b-4723-8272-f461bdc02dc1.h5')\n",
    "glas_gdf['mission'] = \"IS\"\n",
    "\n",
    "# ICESat-2 granule data\n",
    "is2_gdf = ifp.to_geopandas('data/processed_ATL06_20181214041627_11690105_004_01.h5')\n",
    "is2_gdf['mission'] = \"IS2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# first, let's see what's in the harmonized dataframe and its shape.\n",
    "display(preib_gdf.head(), preib_gdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nic, can you introduce the preib data downscaling here? The plotting is super slow because of the data density for preib_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# we do the same for the ICESat/GLAS dataframe\n",
    "display(glas_gdf.head(), glas_gdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# and again for ICESat-2 ATL06\n",
    "display(is2_gdf.head(), is2_gdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's plot all three datasets together, using color to show elevation\n",
    "# Note that although this data is projected, it is not recommended you use this map as a basis for geospatial analysis\n",
    "\n",
    "# Create a Stamen terrain background instance.\n",
    "stamen_terrain = cimgt.Stamen('terrain-background')\n",
    "\n",
    "map_fig = plt.figure()\n",
    "# Create a GeoAxes in the tile's projection.\n",
    "map_ax = map_fig.add_subplot(111, projection=stamen_terrain.crs)\n",
    "\n",
    "# Limit the extent of the map to a small longitude/latitude range.\n",
    "map_ax.set_extent([-56, -45, 67, 71], crs=ccrs.Geodetic())\n",
    "\n",
    "# Add the Stamen data at zoom level 8.\n",
    "map_ax.add_image(stamen_terrain, 8)\n",
    "\n",
    "# world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "# world.plot(ax=map_ax, facecolor=\"lightgray\", edgecolor=\"gray\")\n",
    "\n",
    "# ####ATTN: Need to get the correct projection in here!\n",
    "for onegdf, lab, shp in zip([preib_gdf, glas_gdf, is2_gdf],[\"preib\",\"glas\",\"is2\"], ['P','o','D']):\n",
    "    ms=map_ax.scatter(onegdf[\"longitude\"], onegdf[\"latitude\"],  2, c=onegdf[\"elevation\"],\n",
    "                      vmin=0, vmax=1000, label=lab, marker=shp,\n",
    "                      transform=ccrs.Geodetic())\n",
    "\n",
    "plt.colorbar(ms, label='elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to the harmonization, we can stack our geopandas dataframes to have a unified dataframe for analysis.\n",
    "stacked_df = gpd.GeoDataFrame(pd.concat([preib_gdf, glas_gdf, is2_gdf]))\n",
    "display(stacked_df.head(), stacked_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We zoom in on a very small section of our data to plot a time series\n",
    "tsgdf_full = stacked_df.loc[(stacked_df[\"longitude\"]>=-49.526) & (stacked_df[\"longitude\"]<=-49.521)\n",
    "              & (stacked_df[\"latitude\"]>=69.121) & (stacked_df[\"latitude\"]<=69.125) ]\n",
    "# filter out erroneous elevation values\n",
    "tsgdf_full = tsgdf_full.loc[tsgdf_full[\"elevation\"] > 0]\n",
    "\n",
    "print(len(tsgdf_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to plot as a time series, we cannot have duplicate x (time) values. Since the data collection rates\n",
    "# are on the order of seconds, we keep the average where there are multiple records per second\n",
    "tsgdf = tsgdf_full.groupby('time').mean()\n",
    "\n",
    "# we also need to make \"time\" a non-index column\n",
    "tsgdf[\"time_col\"] = tsgdf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsgdf.plot(x=\"time_col\",y=\"elevation\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use code and example from https://nbviewer.jupyter.org/github/nicholas-kotlinski/2020_ICESat-2_Hackweek_Tutorials/blob/master/05.Geospatial_Analysis/shean_ICESat-2_hackweek_tutorial_GeospatialAnalysis_rendered.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [Draft notebook for April 2021 Earthdata Webinar]\n",
    "\n",
    "#### Learning Objectives (tbd)\n",
    "* (goal from discussion) Introduce audience to the “Ice cubed” (ICESat/OIB/ICESat-2) missions and products\n",
    "* (goal from discussion Promote icepyx and IceFlow as a way to address the need to access/harmonize multiple data products/resolutions/formats/structure\n",
    "\n",
    "\n",
    "#### Webinar Outline\n",
    "* Intro of harmonization challenge\n",
    "    - Moving one level deeper into the need for time series analysis across disparate platforms\n",
    "* Intro to the altimetry missions\n",
    "    - Use the IceFlow intro notebook to guide this\n",
    "    - Highlight the impressive time series\n",
    "* Overview of IceFlow and icepyx\n",
    "    - Audience and use cases of these tools\n",
    "    - Icepyx genesis, open science and community development principles\n",
    "        - working on that balance between community development and end use\n",
    "    - IceFlow overview\n",
    "    - How do these tools address challenges\n",
    "        - IceFlow aims to make it easier to harmonize OIB/ICESat data with ICESat-2 using backend IceFlow API\n",
    "* Use Case / Application\n",
    "    - Leverage ICESat-2 hackweek topics\n",
    "    - https://github.com/ICESAT-2HackWeek/geospatial-analysis/blob/master/shean_ICESat-2_hackweek_tutorial_GeospatialAnalysis.ipynb\n",
    "* Short navigation of nsidc site, how to get to tools, notebook\n",
    "    - Have Jennifer post links while we talk.\n",
    "* Demos\n",
    "    - **Use this notebook to pulls pieces of iceflow / icepyx using a specific science application**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
