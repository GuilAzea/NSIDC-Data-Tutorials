{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuilAzea/NSIDC-Data-Tutorials/blob/main/Copie_de_fine_tuning_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "035kgZ8EwdWn"
      },
      "source": [
        "# Fine Tuning of a ResNet Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmTElCSfdn-W"
      },
      "source": [
        "This notebook explains how to load a geoimagenet dataset, fine-tune and package a ResNet-18 model using the [`thelper` library](https://github.com/plstcharles/thelper).\n",
        "\n",
        "The `thelper` library is a \"training helper\" framework that will manage some of the model training and validation process for you. Its development started at CRIM back in 2018. It works by parsing configuration files (or dictionaries directly) that specify:\n",
        " - what dataset to use;\n",
        " - what model to instantiate;\n",
        " - what data augmentation operations to apply;\n",
        " - which metrics to compute; and\n",
        " - which optimization settings to use.\n",
        "\n",
        "A more popular alternative to `thelper` is `PyTorch-Lightning`, which serves a similar purpose. Do not be afraid to use these, as they will save you a lot of time when starting simple projects!\n",
        "\n",
        "First, we need to install the required libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0upRygsD78S"
      },
      "source": [
        "## GeoImageNet API\n",
        "The API is composed of two parts:\n",
        "- Access to the annotations and the taxonomies: https://geoimagenet.ca/api/v1/redoc\n",
        "- A ML API (restricted to registered users only): https://geoimagenet.ca/ml/api#\n",
        "\n",
        "A Python library is also available containing a few models and utilities:\n",
        "- https://github.com/crim-ca/gin-model-repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbAANhpeTdE3"
      },
      "source": [
        "### Environnement Configuration\n",
        "First, make sure that you have access to a GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCszsKlHzmcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3eb8cf5-389e-4f8c-f170-7270c363fc78"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun  7 16:56:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    37W / 300W |   1697MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8oX1hVrzt2h"
      },
      "source": [
        "In order to use a GPU with your notebook, select the Runtime > Change runtime type menu, and then set the hardware accelerator drop-down to GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTCbXAh_dNhe"
      },
      "source": [
        "%%bash\n",
        "pip3 --quiet install torch torchvision pillow gitpython lz4 matplotlib numpy pyyaml scikit-learn six tqdm h5py opencv-python  pretrainedmodels albumentations pyyaml\n",
        "pip3 --quiet install affine geojson shapely pyproj hdf5plugin\n",
        "pip uninstall thelper\n",
        "rm -rf ./thelper-src\n",
        "git clone  https://github.com/plstcharles/thelper.git thelper-src\n",
        "pip3 install --quiet ./thelper-src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWxnRTp0xMcZ"
      },
      "source": [
        "We also need to install an external repo containing new models as well as useful functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfnyEC4XShsT"
      },
      "source": [
        "%%bash\n",
        "pip uninstall ginmodelrepo\n",
        "rm -rf ./ginmodelrepo-src\n",
        "rm -rf ./ginmodelrepo\n",
        "git clone https://github.com/crim-ca/gin-model-repo ginmodelrepo-src\n",
        "pip3 install --quiet ./ginmodelrepo-src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0TssCLDxcTg"
      },
      "source": [
        "Make sure thelper is imported correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQGmKjyifhmw"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import thelper\n",
        "import ginmodelrepo\n",
        "import json\n",
        "\n",
        "thelper.utils.init_logger()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTnTevFwwVqg"
      },
      "source": [
        "The goal is to fine tune on another dataset called [DeepGlobe](https://arxiv.org/abs/1805.06561). The DeepGlobe Land Cover Classification Challenge is\n",
        "the first public dataset offering high-resolution sub-meter satellite imagery focusing on rural areas. Due to the variety of land cover types and to the density of annotations, this dataset is more challenging than existing counterparts described above. DeepGlobe Land Cover Classification Challenge dataset contains 10146 satellite images of size 20448Ã—20448 pixels in total, split into training/validation/test sets,each with 803 /171/172 images (corresponding to a split of 70%/15%/15%). All images contain RGB data, with a pixel resolution of 50 cm, collected from the DigitalGlobe Vivid+ dataset. The 7 classes are:\n",
        "- Urban land: Man-made, built up areas with human artifacts.\n",
        "- Agriculture land: Farms, any planned (i.e. regular) plantation, cropland, orchards, vineyards, nurseries, and ornamental horticultural areas; confined feeding operations.\n",
        "- Rangeland: Any non-forest, non-farm, green land, grass.\n",
        "- Forest land: Any land with at least 20% tree crown density plus clear cuts.\n",
        "- Water: Rivers, oceans, lakes, wetland, ponds.\n",
        "- Barren land: Mountain, rock, dessert, beach, land with no vegetation\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1u3lSw0z9R0P8HXxH5Ljsk0ybQdzmAcmp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_qgXYu1Emzb"
      },
      "source": [
        "ginmodelrepo.util.maybe_download_and_extract('1-tjv9gznTAM_VEaCeqz9k77fJrvVoTBw','/content/deepglobe_train.zip')\n",
        "#ginmodelrepo.util.maybe_download_and_extract('12_e0dDwFDDIJTNDIBLVzJovs1YhxRhpg','/content/train/gin.zip')\n",
        "# !unzip deepglobe_train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkcqYC9ZUDiB"
      },
      "source": [
        "%%bash\n",
        "cd /content/train/\n",
        "ls -l *.tif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5VFi1HO9jQ"
      },
      "source": [
        "## Training Session Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6guok64yTkV"
      },
      "source": [
        "Name your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfvP5X9adOcp"
      },
      "source": [
        "session_name = 'gin-resnet'\n",
        "dataset_name = 'gin'\n",
        "DATASET_ROOT = '/content/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0dDC81QLs5h"
      },
      "source": [
        "Open the training set json file in order to prepare the data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_dfRRvLWhGa"
      },
      "source": [
        "# Opening JSON file\n",
        "with open('/content/train/meta.json') as json_file:\n",
        "  meta = json.load(json_file)\n",
        "  dataset= {'path': DATASET_ROOT, ginmodelrepo.util.DATASET_DATA_KEY : meta}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOY0uVxML_Fe"
      },
      "source": [
        "We check the available classes in the training set, it is important to specify the right split (train or test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOHUwaSMXGvP"
      },
      "source": [
        "taxo_name = 'Land cover'\n",
        "split = 'train'\n",
        "class_mapping, all_classes_with_files, all_classes_names, classes_per_taxo, datasets_per_taxo = ginmodelrepo.util.get_dataset_classes(dataset, min_occurence = 5)\n",
        "class_mapping = datasets_per_taxo[taxo_name]['class_mapping']\n",
        "print(class_mapping)\n",
        "inv_class_mapping = {str(v):k for k,v in class_mapping.items()}\n",
        "if len(all_classes_with_files) == 0:\n",
        "  raise ValueError(\"No data for split '{}'\".format(split))\n",
        "dataset[ginmodelrepo.util.DATASET_DATA_KEY][ginmodelrepo.util.DATASET_DATA_PATCH_KEY]= datasets_per_taxo[taxo_name]['data']\n",
        "print(all_classes_with_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvndlEg9UjHS"
      },
      "source": [
        "print(ginmodelrepo.util..DATASET_DATA_PATCH_MASK_KEY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsjph7luL2Fz"
      },
      "source": [
        "Optionally, we can add the background class (everything else outside the masks) or ignore the 0 value in the masks (`dontcare = -1`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQYP3-s8L9GW"
      },
      "source": [
        "dontcare = -1 #  ignore the 0 value in the masks\n",
        "if dontcare is None:\n",
        "  class_mapping = {'Background': 999, **class_mapping}\n",
        "n_classes = len(class_mapping.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSt4JYlAME0y"
      },
      "source": [
        "We configure the classification task in thelper:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwclY5X5bJLR"
      },
      "source": [
        "task_config = {\n",
        "  \"type\": \"thelper.tasks.Classification\",\n",
        "  \"params\": {\n",
        "      \"class_names\": list(dict(class_mapping).keys()),\n",
        "      \"input_key\": \"data\",\n",
        "      \"label_key\": \"label\"\n",
        "  }\n",
        "}\n",
        "task = ginmodelrepo.util.update_class_mapping(class_mapping, task_config)\n",
        "print(task)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuVTl7VaMVp8"
      },
      "source": [
        "We configure the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj85pr3Jbj7c"
      },
      "source": [
        "\n",
        "datasets_train= ginmodelrepo.util.adapt_dataset_for_model_task(task, dataset, 'train')\n",
        "#datasets_valid= ginmodelrepo.util.adapt_dataset_for_model_task(task, dataset, 'test')\n",
        "datasets_config = {\n",
        "  'gin_train': datasets_train,\n",
        "  #'gin_valid': datasets_valid,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjBNbEEoMdl7"
      },
      "source": [
        "The base transforms will be applied by the data loader in order to pre-process the images before training. Note that it is important to precise the `target_key` for transforms applicable to the images only (and not the masks):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBRVfzARmZoT"
      },
      "source": [
        "base_transforms= [\n",
        "  {\n",
        "      \"operation\": \"thelper.transforms.SelectChannels\",\n",
        "      \"params\": {\"channels\": [0, 1, 2]},\n",
        "      \"target_key\": \"data\", # here we specify that only the transform is applied on the data and not the mask\n",
        "  },\n",
        "  {\n",
        "      \"operation\": \"thelper.transforms.CenterCrop\",\n",
        "      \"params\": {\"size\": 128},\n",
        "  },\n",
        "  {\n",
        "      \"operation\": \"thelper.transforms.NormalizeMinMax\",\n",
        "      \"params\": {\"min\": 0.0, \"max\": 255.0},\n",
        "      \"target_key\": \"data\",\n",
        "  },\n",
        "  {\n",
        "      \"operation\": \"thelper.transforms.NormalizeZeroMeanUnitVar\",\n",
        "      \"params\": {\n",
        "          \"mean\": [0.485, 0.456, 0.406],\n",
        "          \"std\": [0.229, 0.224, 0.225]\n",
        "      },\n",
        "      \"target_key\": \"data\",\n",
        "  },\n",
        "  {\n",
        "      \"operation\": \"thelper.transforms.Transpose\",\n",
        "      \"params\": {\n",
        "          \"axes\": [2,0,1]\n",
        "      },\n",
        "      \"target_key\": \"data\",\n",
        "  },\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd-YQZmfM-7-"
      },
      "source": [
        "Data loader creation, we need to specify the train/validation split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXlMGXXpdjID"
      },
      "source": [
        "loaders_config = {\n",
        "    \"base_transforms\": base_transforms,\n",
        "    \"batch_size\": 16,\n",
        "    \"workers\": 2,\n",
        "    \"pin_memory\": True,\n",
        "    \"train_split\": {\n",
        "        \"gin_train\": 0.8  # 80% of dataset goes to training set\n",
        "    },\n",
        "    \"valid_split\": {\n",
        "        \"gin_train\": 0.2  # remaining 20% goes to validation set\n",
        "    }\n",
        "}\n",
        "\n",
        "data_config = {\"datasets\": datasets_config, \"loaders\": loaders_config}\n",
        "save_dir = None\n",
        "task, train_loader, valid_loader, test_loader = thelper.data.create_loaders(data_config, save_dir=save_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z92gt7zji6p"
      },
      "source": [
        "### Minibatch Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GorzPqyDjoDA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "print(f\"train minibatch count: {len(train_loader)}\")\n",
        "print(inv_class_mapping)\n",
        "samples = next(iter(train_loader))\n",
        "print(samples['label'])\n",
        "print(f\"images tensor shape: {samples['data'].shape}\")  # BxCxHxW\n",
        "print(f\"labels tensor shape: {samples['label'].shape}\")  # Bx1  (une Ã©tiquette par image du minibatch)\n",
        "batch_size = samples['data'].shape[0]\n",
        "display_batch_size = min(8, batch_size)\n",
        "fig = plt.figure(figsize=(24, 6))\n",
        "for r, key in enumerate(['data']):\n",
        "  for ax_idx in range(display_batch_size):\n",
        "    ax = fig.add_subplot(1, 8, ax_idx + 1 + r*8)\n",
        "    ax.grid(False)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    class_name = inv_class_mapping[task.class_names[samples['label'][ax_idx].numpy()]]\n",
        "    # class_name = samples['label'][ax_idx].numpy()\n",
        "    # class_name = samples['name']\n",
        "    ax.set_title(f\"{class_name}\")\n",
        "    display = samples[key][ax_idx, ...].numpy()\n",
        "    if r == 0:\n",
        "      display = display.transpose((1, 2, 0))  # CxHxW => HxWxC (tel que demandÃ© par matplotlib)\n",
        "      display = 128 * display + 127  # on inverse la normalisation\n",
        "    display = cv.normalize(display, dst=None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX, dtype=cv.CV_8U)\n",
        "    plt.imshow(display)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-fc0JUHNMi7"
      },
      "source": [
        "### Model Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP_jpZVvKvRz"
      },
      "source": [
        "We are training a ResNet-18 neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoMp3A6UgcJF"
      },
      "source": [
        "model_config = {\n",
        "    \"type\": \"torchvision.models.resnet18\",\n",
        "        \"params\": {\"pretrained\": True},\n",
        "}\n",
        "model = thelper.nn.create_model({\"model\": model_config}, task)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XhEHR5COnSj"
      },
      "source": [
        "### Trainer Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYmsGo1che2t"
      },
      "source": [
        "Gather the parameters to be optimized/updated in this run. If we are finetuning we will be updating all parameters. However, if we are doing feature extract method, we will only update the parameters that we have just  initialized, i.e. the parameters with `requires_grad = True`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGebQRRAiSUG"
      },
      "source": [
        "base_lr = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7utYgG7hdix"
      },
      "source": [
        "params_to_update = model.parameters()\n",
        "n_param = 0\n",
        "name_block = dict()\n",
        "lr_blcok = dict()\n",
        "for l, (name,param) in enumerate(model.named_parameters()):\n",
        "    n_param += 1\n",
        "for l, (name,param) in enumerate(model.named_parameters()):\n",
        "    blcok = name.split('.')[0]\n",
        "    name_block[l] = name\n",
        "    lr_blcok[l] = base_lr * 10**(2*(l/n_param-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Weasp7eIcrn"
      },
      "source": [
        "print(lr_blcok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNV7BenKP26e"
      },
      "source": [
        "We turn off the model update for half the model (only the classifier and the last layer will be modified)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg1o548Gjf34"
      },
      "source": [
        "params_to_update = []\n",
        "#name_block = set(name_block)\n",
        "for l, (name,param) in enumerate(model.named_parameters()):\n",
        "  if l < int(3*n_param/4):\n",
        "    param.requires_grad = False # we are freezing part of the ResNet\n",
        "  else:\n",
        "    params_to_update.append({\n",
        "        \"params\": param,\n",
        "        \"lr\": lr_blcok[l],# you can choose to apply different lr value for each layer\n",
        "    })\n",
        "  if param.requires_grad == True:\n",
        "      print(\"\\t\",name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlslyZReNazS"
      },
      "source": [
        "### Training Session Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDiKsUu3kjkR"
      },
      "source": [
        "optimizer_config = {\n",
        "    \"loss\": {\"type\": \"torch.nn.CrossEntropyLoss\"},\n",
        "    \"optimizer\": torch.optim.SGD(params_to_update, lr= base_lr, momentum=0.9, weight_decay=0.001),\n",
        "}\n",
        "trainer_config = {\n",
        "    \"epochs\": 30,# 20 epochs\n",
        "    \"tbx\": True, # turn on the tensorboard logs\n",
        "    \"monitor\": \"accuracy\",\n",
        "    \"optimization\": optimizer_config,\n",
        "    \"metrics\": {\n",
        "        \"accuracy\": {\"type\": \"thelper.optim.Accuracy\"},\n",
        "    }\n",
        "}\n",
        "loaders = (train_loader, valid_loader, test_loader)\n",
        "trainer = thelper.train.create_trainer(session_name=\"gin_training\",\n",
        "                                       save_dir=\"./gin_training\",\n",
        "                                       config={\"trainer\": trainer_config},\n",
        "                                       model=model,\n",
        "                                       task=task,\n",
        "                                       loaders=loaders)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMDlqQpsNgCT"
      },
      "source": [
        "### Launch the training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t18ppvfjtMTM"
      },
      "source": [
        "The tensorboard below will track metrics once the training is launched, it must be launched first then hit refresh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XPcbFmUk8xt",
        "collapsed": true
      },
      "source": [
        "#outputs = trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC70lu2vnIat"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjxMkOZal9eL"
      },
      "source": [
        "%tensorboard --logdir /content/gin_training/output/gin_training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfstlyiTN5Xp"
      },
      "source": [
        "### Export the Model\n",
        "Once the training is done we can package and export the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qS_GXn-N3m_"
      },
      "source": [
        "config = thelper.utils.load_checkpoint('/content/gin_training/checkpoints/ckpt.best.pth')\n",
        "model_config = {\n",
        "    \"type\": config[\"model_type\"],\n",
        "    \"params\": config[\"model_params\"],\n",
        "    'weights': config[\"model\"],\n",
        "}\n",
        "config[\"model\"] = model_config\n",
        "config[\"datasets\"] = datasets_config\n",
        "config[\"loaders\"] = loaders_config\n",
        "config[\"trainer\"] = {}\n",
        "\n",
        "thelper.cli.export_model(config, '/content/export/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9R3_OkA-ZRI"
      },
      "source": [
        "print(config)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}